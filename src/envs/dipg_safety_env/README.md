# DIPG Safety Environment (DIPGSafetyEnv)

## Overview

The `DIPGSafetyEnv` is a custom environment built on the OpenEnv framework for Reinforcement Learning research in high-stakes AI safety. It was developed to address a critical use case: ensuring the reliability and safety of a Large Language Model (LLM) agent operating in the medical domain of **Diffuse Intrinsic Pontine Glioma (DIPG)**, a universally fatal pediatric brain tumor.

In this context, an AI's failure is not an option. The environment's primary purpose is to train and rigorously evaluate an agent's ability to:
1.  Base its answers *only* on the verified clinical context provided.
2.  Correctly identify and report conflicting information from different sources.
3.  Safely abstain from answering when the context is insufficient.
4.  Strictly avoid hallucinating facts or providing unsafe, unsupported information.

## Features

The environment server contains a suite of safety-critical reward functions that score an agent's response based on the following behaviors:

*   **Conflict Identification:** Rewards the agent for correctly stating that provided sources are contradictory.
*   **Knowledge Abstention:** Rewards the agent for recognizing when a question cannot be answered from the given text and explicitly saying so.
*   **Format Adherence:** Positively or negatively scores the response based on its adherence to a required structured output format.
*   **Hallucination Penalty:** Heavily penalizes the agent for generating any information that is not supported by the provided context.

## Getting Started: How to Use the Environment

The `DIPGSafetyEnv` follows a standard client-server model.

### 1. Running the Server

The server requires the custom synthetic dataset (`harmonic_reasoner_dataset_structured.jsonl`) to be present in its directory. The easiest way to run the server is as a background process from a script or notebook.

```python
import subprocess
import sys
import os
import time

# Ensure the dataset file is in the server's directory first.
# !mv /path/to/your/harmonic_reasoner_dataset_structured.jsonl ./src/envs/dipg_safety_env/server/

port = "8009"
localhost = f"http://localhost:{port}"

# Start the server process from the 'src' directory of the OpenEnv project
openenv_process = subprocess.Popen(
    [sys.executable, "-m", "uvicorn", "envs.dipg_safety_env.server.app:app", "--host", "0.0.0.0", "--port", port],
    env={**os.environ, "PYTHONPATH": "./src"},
    cwd="./src",
)

# Wait for the server to initialize
time.sleep(15)
print("Server process started.")
```

### 2. Interacting from the Client

Once the server is running, an agent can interact with it using the `DIPGSafetyEnv` client.

```python
from envs.dipg_safety_env.client import DIPGSafetyEnv
from envs.dipg_safety_env.models import DIPGAction

# Connect to the running server
env = DIPGSafetyEnv(base_url="http://localhost:8009", timeout=60)

# Start a new episode and get the first challenge
# The 'obs' object will contain a medical context and a question.
obs = env.reset()
print(f"Question: {obs.question}")

# The agent processes the observation and generates a response
agent_response_text = "Based on the provided context, the information is conflicting."

# Send the response (as an Action) to the environment to be scored
action = DIPGAction(llm_response=agent_response_text)
result = env.step(action)

# The result contains the reward and a flag indicating the episode is done
print(f"Reward: {result.reward}")
print(f"Done: {result.done}")
```

## Running Tests

The environment includes a suite of unit tests to ensure its core logic is working correctly. These tests verify that the environment can be reset, that actions are processed, and that the internal state is managed properly.

### Prerequisites

You must have `pytest` installed:
```bash
pip install pytest
```

### How to Run

From the **root directory** of the `OpenEnv` project, run the following command:

```bash
pytest src/envs/dipg_safety_env/server/test_dipg_safety_env.py
```

A successful run will show an output indicating that all tests passed, for example:
```
============================= test session starts ==============================
...
collected 4 items

src/envs/dipg_safety_env/server/test_dipg_safety_env.py ....         [100%]

============================== 4 passed in 0.50s ===============================
```

## Core Components

*   **`models.py`**: Defines the data structures for interaction:
    *   `DIPGObservation`: Contains the `context` and `question` served to the agent.
    *   `DIPGAction`: Contains the `llm_response` generated by the agent.
*   **`server/dipg_environment.py`**: The core of the environment. It loads the dataset, serves challenges via `reset()`, and calculates rewards via `step()`.
*   **`client.py`**: The "remote control" that allows a Python script to communicate with the server over HTTP, handling all the JSON serialization and parsing.
*   **`server/test_dipg_safety_env.py`**: Unit tests for verifying the environment's functionality.